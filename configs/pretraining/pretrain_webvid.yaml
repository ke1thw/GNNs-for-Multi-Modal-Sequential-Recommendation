# wandb
wandb_enable: False
project_name: ""
display_name: ""


# dataset
# - basic
num_worker: 8
# - train
train_item_file: "./dataset/webvid/processed/train_item.jsonl"
train_seq_file: "./dataset/webvid/processed/train_seq.jsonl"
# - eval
eval_item_file: "./dataset/msrvtt/processed/eval_item.jsonl"
eval_seq_file: "./dataset/msrvtt/processed/eval_seq.jsonl"
# - seq
max_seq_length: 100
# - vision    ["mp4", "embed", ~]
train_vision_format: "embed"
eval_vision_format: "mp4"
max_vision_frames: 10
# - text    ["txt", "embed", ~]
train_text_format: "txt"
eval_text_format: "txt"


# model
clip_model_path: "./weights/clip/ViT-B-32.pt"
# - feature data
vision_feature_embed_dim: 512
text_feature_embed_dim: 512
# - fusion model
fusion_embed_dim: 512
fusion_layers: 2
fusion_heads: 8
fusion_feedforward_dim: 1024
fusion_dropout: 0.5
fusion_embed_dropout: 0.2
initializer_range: 0.02


# train
# - basic
seed: 42
log_file: "./logs/pretrain-webvid-2layer-512dim.log"
# - dataloader
train_batch_size: 6000
eval_batch_size: 100
# - train
num_train_epochs: 50
learning_rate: 5.0e-5
lr_scheduler_gamma: 0.90
max_grad_norm: 1.0
contrastive_temperature: 0.05
# - save
save_epochs: 1
model_save_path: "./weights/pretrain-webvid-2layer-512dim"
model_resume_checkpoint: ~          # ["path/to/checkpoint", ~]





